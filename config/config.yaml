# DevPlan Orchestrator Configuration

# Global LLM Provider Configuration (fallback for all stages)
# These map directly to AppConfig.llm.* via src/config.py.
llm_provider: requesty          # Options: openai, generic, aether, agentrouter, requesty
model: openai/gpt-5-mini       # Primary/interview model (can be overridden by MODEL env)
temperature: 0.7
max_tokens: 20000

# Per-Stage LLM Configuration (optional overrides)
# These map to AppConfig.*_llm via src/config.py:_load_llm_config.
# Use them when you want explicit stage-specific behavior instead of relying on MODEL/FINAL_MODEL.
#
# Interview stage overrides (optional) - Project discovery conversation
# interview_llm_provider: requesty
# interview_model: openai/gpt-5-mini
# interview_temperature: 0.8
# interview_max_tokens: 4096
# interview_api_timeout: 120
#
# Complexity analysis stage overrides (optional) - Analyzes project scope
# complexity_llm_provider: requesty
# complexity_model: openai/gpt-5-mini
# complexity_temperature: 0.3
# complexity_max_tokens: 4096
# complexity_api_timeout: 120
#
# Design stage overrides (optional)
# design_llm_provider: requesty
# design_model: openai/gpt-5-mini
# design_temperature: 0.7
# design_max_tokens: 20000
# design_api_timeout: 300
# design_reasoning_effort: medium  # one of: low, medium, high
#
# Validation stage overrides (optional) - Validates generated design
# validation_llm_provider: requesty
# validation_model: openai/gpt-5-mini
# validation_temperature: 0.2
# validation_max_tokens: 8192
# validation_api_timeout: 180
#
# Correction stage overrides (optional) - Fixes validation issues
# correction_llm_provider: requesty
# correction_model: openai/gpt-5
# correction_temperature: 0.4
# correction_max_tokens: 20000
# correction_api_timeout: 300
#
# DevPlan/Plan stage overrides (optional)
devplan_llm_provider: requesty
devplan_model: openai/gpt-5
devplan_temperature: 0.3
devplan_max_tokens: 81920
devplan_api_timeout: 300
#
# Execute stage overrides (optional) - Phase execution/expansion
# execute_llm_provider: requesty
# execute_model: openai/gpt-5
# execute_temperature: 0.5
# execute_max_tokens: 40000
# execute_api_timeout: 300
#
# Handoff stage overrides (optional)
handoff_llm_provider: requesty
handoff_model: openai/gpt-5
handoff_temperature: 0.5
handoff_max_tokens: 86000
handoff_api_timeout: 300
#
# You can also set per-stage API keys via environment variables:
# INTERVIEW_API_KEY=sk-...
# COMPLEXITY_API_KEY=sk-...
# DESIGN_API_KEY=sk-...
# VALIDATION_API_KEY=sk-...
# CORRECTION_API_KEY=sk-...
# DEVPLAN_API_KEY=sk-...
# EXECUTE_API_KEY=sk-...
# HANDOFF_API_KEY=sk-...

# API Configuration
api_timeout: 300  # Request timeout in seconds
max_concurrent_requests: 5  # Maximum number of concurrent API calls

# Retry Configuration
retry:
  max_attempts: 3  # Maximum number of retry attempts
  initial_delay: 1  # Initial delay in seconds
  max_delay: 60  # Maximum delay in seconds
  exponential_base: 2  # Exponential backoff base

# Streaming Configuration
streaming_enabled: false  # Enable/disable token streaming (global fallback)
streaming_callback: null  # Custom streaming callback function

# Phase-Specific Streaming Environment Variables:
# These can be set via environment variables to override global streaming:
# STREAMING_DESIGN_ENABLED=true/false    # Design phase streaming
# STREAMING_DEVPLAN_ENABLED=true/false   # DevPlan phase streaming
# STREAMING_HANDOFF_ENABLED=true/false   # Handoff phase streaming
#
# Priority: phase-specific → global → config → false (default)
# Phase-specific settings override global streaming setting

# Output Configuration
output_dir: ./docs  # Directory for generated documentation
state_dir: ./.devussy_state  # Directory for state persistence

# Logging Configuration
log_level: INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
log_file: logs/devussy.log  # Log file path
log_format: "[%(asctime)s] %(levelname)s - %(name)s - %(message)s"

# Git Configuration
git_enabled: true  # Enable/disable automatic git commits
git_commit_after_design: true
git_commit_after_devplan: true
git_commit_after_handoff: true

# Documentation Configuration
documentation:
  auto_generate: true  # Automatically generate documentation
  include_citations: true  # Include citations in documentation
  timestamp_updates: true  # Add timestamps to documentation updates
  generate_index: true  # Generate documentation index

# Pipeline Configuration
pipeline:
  save_intermediate_results: true  # Save intermediate pipeline results
  validate_output: true  # Validate pipeline output
  enable_checkpoints: true  # Enable progress checkpoints for resumable workflows

# Detour experimentation toggles
detour:
  enabled: true  # Master switch for detour behaviors
  instrumentation_enabled: true  # Collect detailed timing/metrics per stage
  metadata_logging_enabled: true  # Log metadata write frequency/size
