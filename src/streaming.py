"""Streaming handler for real-time token display during LLM generation.

This module provides StreamingHandler class to capture and display tokens
as they are generated by LLM clients, supporting both console output and
optional file logging.
"""

from __future__ import annotations

import asyncio
import sys
import time
from pathlib import Path
from typing import Any, Callable, Optional, TextIO


class StreamingHandler:
    """Handler for streaming token generation with real-time display.

    Supports both console output and optional file logging of streamed tokens.
    Works with both async and sync streaming contexts.
    """

    def __init__(
        self,
        enable_console: bool = True,
        log_file: Optional[Path] = None,
        flush_interval: float = 0.05,
        prefix: str = "",
    ) -> None:
        """Initialize streaming handler.

        Args:
            enable_console: Whether to display tokens to console
            log_file: Optional file path to log streaming output
            flush_interval: Minimum time between console flushes
            prefix: Optional prefix to display before streamed content
        """
        self.enable_console = enable_console
        self.log_file = log_file
        self.flush_interval = flush_interval
        self.prefix = prefix
        self._last_flush = 0.0
        self._buffer = []
        self._file_handle: Optional[TextIO] = None

    async def __aenter__(self) -> StreamingHandler:
        """Async context manager entry."""
        if self.log_file:
            self._file_handle = open(self.log_file, "a", encoding="utf-8")
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb) -> None:
        """Async context manager exit."""
        await self.flush()
        if self._file_handle:
            self._file_handle.close()
            self._file_handle = None

    def on_token(self, token: str) -> None:
        """Handle a single token from the stream.

        Args:
            token: The token text to display/log
        """
        self._buffer.append(token)

        # Write to file immediately if enabled
        if self._file_handle:
            self._file_handle.write(token)
            self._file_handle.flush()

        # Console output with rate limiting
        if self.enable_console:
            current_time = time.time()
            if current_time - self._last_flush >= self.flush_interval:
                self._flush_console()
                self._last_flush = current_time

    async def on_token_async(self, token: str) -> None:
        """Async version of on_token for compatibility.

        Args:
            token: The token text to display/log
        """
        self.on_token(token)
        # Allow other coroutines to run
        await asyncio.sleep(0)

    def on_completion(self, full_text: str) -> None:
        """Handle completion of streaming.

        Args:
            full_text: The complete generated text
        """
        # Final flush to ensure all tokens are displayed
        if self.enable_console:
            self._flush_console()
            if self.prefix:
                print()  # New line after completion

    async def on_completion_async(self, full_text: str) -> None:
        """Async version of on_completion.

        Args:
            full_text: The complete generated text
        """
        await self.flush()
        if self.enable_console and self.prefix:
            print()  # New line after completion

    def _flush_console(self) -> None:
        """Flush buffered tokens to console."""
        if not self._buffer:
            return

        if self.prefix and len(self._buffer) == len("".join(self._buffer)):
            # First tokens - show prefix
            sys.stdout.write(f"{self.prefix}")

        for token in self._buffer:
            sys.stdout.write(token)

        sys.stdout.flush()
        self._buffer.clear()

    async def flush(self) -> None:
        """Flush any remaining buffered content."""
        if self.enable_console:
            self._flush_console()

        if self._file_handle:
            self._file_handle.flush()

    def create_callback(self) -> Callable[[str], None]:
        """Create a callback function for use with streaming APIs.

        Returns:
            Function that can be passed to streaming APIs
        """
        return self.on_token

    def create_async_callback(self) -> Callable[[str], Any]:
        """Create an async callback function for use with streaming APIs.

        Returns:
            Async function that can be passed to streaming APIs
        """
        return self.on_token_async

    @classmethod
    def create_console_handler(cls, prefix: str = "") -> StreamingHandler:
        """Create a handler that only outputs to console.

        Args:
            prefix: Optional prefix to display before content

        Returns:
            StreamingHandler configured for console output
        """
        return cls(enable_console=True, prefix=prefix)

    @classmethod
    def create_file_handler(cls, log_file: Path, prefix: str = "") -> StreamingHandler:
        """Create a handler that logs to file and console.

        Args:
            log_file: Path to log file
            prefix: Optional prefix to display before content

        Returns:
            StreamingHandler configured for file and console output
        """
        return cls(enable_console=True, log_file=log_file, prefix=prefix)

    @classmethod
    def create_quiet_handler(cls, log_file: Path) -> StreamingHandler:
        """Create a handler that only logs to file (no console output).

        Args:
            log_file: Path to log file

        Returns:
            StreamingHandler configured for file-only output
        """
        return cls(enable_console=False, log_file=log_file)


class StreamingSimulator:
    """Utility class to simulate streaming from non-streaming APIs.

    Breaks complete responses into tokens for display purposes.
    """

    def __init__(
        self,
        chunk_size: int = 3,
        delay: float = 0.02,
        word_boundary: bool = True,
    ) -> None:
        """Initialize streaming simulator.

        Args:
            chunk_size: Characters per simulated token
            delay: Delay between tokens in seconds
            word_boundary: Whether to break on word boundaries when possible
        """
        self.chunk_size = chunk_size
        self.delay = delay
        self.word_boundary = word_boundary

    async def simulate_streaming(
        self,
        text: str,
        callback: Callable[[str], Any],
    ) -> None:
        """Simulate streaming by chunking complete text.

        Args:
            text: Complete text to stream
            callback: Function to call with each chunk
        """
        if not text:
            return

        chunks = self._create_chunks(text)

        for chunk in chunks:
            if asyncio.iscoroutinefunction(callback):
                await callback(chunk)
            else:
                callback(chunk)

            if self.delay > 0:
                await asyncio.sleep(self.delay)

    def _create_chunks(self, text: str) -> list[str]:
        """Break text into streaming chunks.

        Args:
            text: Text to chunk

        Returns:
            List of text chunks
        """
        if not self.word_boundary:
            # Simple character-based chunking
            return [
                text[i : i + self.chunk_size]
                for i in range(0, len(text), self.chunk_size)
            ]

        # Word-boundary aware chunking
        chunks = []
        words = text.split()
        current_chunk = ""

        for word in words:
            if len(current_chunk + word) <= self.chunk_size:
                current_chunk += word + " "
            else:
                if current_chunk:
                    chunks.append(current_chunk.rstrip())
                current_chunk = word + " "

        # Add remaining chunk
        if current_chunk:
            chunks.append(current_chunk.rstrip())

        return chunks
